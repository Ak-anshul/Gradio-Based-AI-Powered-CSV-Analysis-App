{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af2c371e-516a-4bc0-9517-277fefcd4004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (5.20.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: ollama in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (0.4.7)\n",
      "Requirement already satisfied: pydantic_ai in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (0.0.36)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (4.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.115.11)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.7.2 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (1.7.2)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.27.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.29.2)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (3.10.7)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (10.2.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (2.10.6)\n",
      "Requirement already satisfied: pydub in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.9.10)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.46.1)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.12.5)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio) (0.31.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio-client==1.7.2->gradio) (2023.10.0)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from gradio-client==1.7.2->gradio) (13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: pydantic-ai-slim==0.0.36 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (0.0.36)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic-ai-slim==0.0.36->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (0.2.2)\n",
      "Requirement already satisfied: griffe>=1.3.2 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic-ai-slim==0.0.36->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (1.6.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.28.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic-ai-slim==0.0.36->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (1.30.0)\n",
      "Requirement already satisfied: pydantic-graph==0.0.36 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic-ai-slim==0.0.36->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (0.0.36)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic-ai-slim==0.0.36->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (0.4.0)\n",
      "Requirement already satisfied: anthropic>=0.49.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (0.49.0)\n",
      "Requirement already satisfied: boto3>=1.34.116 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (1.37.10)\n",
      "Requirement already satisfied: argcomplete>=3.5.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (3.6.0)\n",
      "Requirement already satisfied: prompt-toolkit>=3 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (3.0.43)\n",
      "Requirement already satisfied: rich>=13 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (13.3.5)\n",
      "Requirement already satisfied: cohere>=5.13.11 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (5.14.0)\n",
      "Requirement already satisfied: groq>=0.12.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (0.18.0)\n",
      "Requirement already satisfied: mistralai>=1.2.5 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (1.5.1)\n",
      "Requirement already satisfied: openai>=1.65.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (1.65.5)\n",
      "Requirement already satisfied: google-auth>=2.36.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (2.38.0)\n",
      "Requirement already satisfied: requests>=2.32.3 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (2.32.3)\n",
      "Requirement already satisfied: logfire-api>=1.2.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic-graph==0.0.36->pydantic-ai-slim==0.0.36->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (3.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.13.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.65.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from anthropic>=0.49.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (1.8.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from anthropic>=0.49.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (0.9.0)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.10 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from boto3>=1.34.116->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (1.37.10)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from boto3>=1.34.116->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from boto3>=1.34.116->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (0.11.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (1.10.0)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (0.4.0)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (0.19.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (2.32.0.20250306)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from google-auth>=2.36.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from google-auth>=2.36.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from google-auth>=2.36.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (4.9)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from mistralai>=1.2.5->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (1.0.6)\n",
      "Requirement already satisfied: typing-inspect>=0.9.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from mistralai>=1.2.5->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (0.9.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.28.0->pydantic-ai-slim==0.0.36->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.28.0->pydantic-ai-slim==0.0.36->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (7.0.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from prompt-toolkit>=3->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (0.2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from requests>=2.32.3->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from requests>=2.32.3->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (2.0.7)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from rich>=13->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from rich>=13->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (2.15.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.28.0->pydantic-ai-slim==0.0.36->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (1.14.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.28.0->pydantic-ai-slim==0.0.36->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (3.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=13->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (0.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.36.0->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (0.4.8)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\hp8cg\\anaconda3\\lib\\site-packages (from typing-inspect>=0.9.0->mistralai>=1.2.5->pydantic-ai-slim[anthropic,bedrock,cli,cohere,groq,mistral,openai,vertexai]==0.0.36->pydantic_ai) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio pandas ollama pydantic_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38204f90-b153-4310-88f5-0f044ac8eb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ollama version is 0.5.13\n"
     ]
    }
   ],
   "source": [
    "!ollama --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dbdab97-24bf-4f1d-bb8e-0dfc7500f3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               ID              SIZE      MODIFIED      \n",
      "llama3:8b          365c0bd3c000    4.7 GB    9 minutes ago    \n",
      "llama3.1:latest    46e0c10c039e    4.9 GB    18 hours ago     \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f760392-a1ee-4e4b-b102-185cc028bf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest Ã¢Â â€¹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest Ã¢Â â„¢ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest Ã¢Â Â¹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest Ã¢Â Â¸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest Ã¢Â Â¼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest Ã¢Â Â´ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest Ã¢Â Â¦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest Ã¢Â Â§ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest Ã¢Â â€¡ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest Ã¢Â ï¿½ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest Ã¢Â â€¹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest Ã¢Â â„¢ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest Ã¢Â Â¹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 6a0746a1ec1a... 100% Ã¢â€“â€¢Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“ï¿½ 4.7 GB                         \u001b[K\n",
      "pulling 4fa551d4f938... 100% Ã¢â€“â€¢Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“ï¿½  12 KB                         \u001b[K\n",
      "pulling 8ab4849b038c... 100% Ã¢â€“â€¢Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“ï¿½  254 B                         \u001b[K\n",
      "pulling 577073ffcc6c... 100% Ã¢â€“â€¢Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“ï¿½  110 B                         \u001b[K\n",
      "pulling 3f8eb4da87fa... 100% Ã¢â€“â€¢Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“ï¿½  485 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3:8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5945f621-857e-4a1f-96b0-7974cf4266fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABC', 'ALLOW_MODEL_REQUESTS', 'AsyncIterator', 'Iterator', 'KnownModelName', 'Literal', 'Model', 'ModelMessage', 'ModelRequestParameters', 'ModelResponse', 'ModelResponsePartsManager', 'ModelResponseStreamEvent', 'ModelSettings', 'StreamedResponse', 'TYPE_CHECKING', 'Usage', 'UserError', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_annotations', '_cached_async_http_client', 'abstractmethod', 'asynccontextmanager', 'cache', 'cached_async_http_client', 'check_allow_model_requests', 'contextmanager', 'dataclass', 'datetime', 'field', 'get_user_agent', 'httpx', 'infer_model', 'instrumented', 'override_allow_model_requests', 'wrapper']\n"
     ]
    }
   ],
   "source": [
    "import pydantic_ai.models\n",
    "print(dir(pydantic_ai.models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7af0c21d-ffe7-40c9-9046-38e3355c08a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gradio as gr\n",
    "import ollama\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pydantic_ai.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "301ca95d-094e-4e9f-81b7-13ff848087db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7872\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = \"llama3:8b\"  \n",
    "\n",
    "df = None  # Global variable to store the uploaded DataFrame\n",
    "\n",
    "\n",
    "class CSVQueryModel(Model):\n",
    "    \"\"\"AI model processes natural language queries about CSV data.\"\"\"\n",
    "    question: str\n",
    "\n",
    "# Function to load CSV with validation\n",
    "def load_csv(file):\n",
    "    global df\n",
    "    try:\n",
    "        if not file:\n",
    "            return \"âš ï¸ No file uploaded!\", gr.update(choices=[]), gr.update(choices=[])\n",
    "        \n",
    "        df = pd.read_csv(file.name)\n",
    "        \n",
    "        if df.empty:\n",
    "            return \"âš ï¸ Uploaded CSV is empty!\", gr.update(choices=[]), gr.update(choices=[])\n",
    "        \n",
    "        column_list = df.columns.tolist()\n",
    "        return (\n",
    "            f\"âœ… CSV Loaded Successfully! Columns: {', '.join(column_list)}\",\n",
    "            gr.update(choices=column_list, value=column_list[0] if column_list else None),\n",
    "            gr.update(choices=column_list, value=column_list[1] if len(column_list) > 1 else None)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return (f\"âŒ Error loading CSV: {str(e)}\", gr.update(choices=[]), gr.update(choices=[]))\n",
    "\n",
    "# Function to process query using Llama3:8b model\n",
    "\n",
    "def answer_query(question):\n",
    "    global df\n",
    "    if df is None:\n",
    "        return \"âš ï¸ Please upload a CSV file first.\"\n",
    "    \n",
    "    try:\n",
    "        csv_data = df.head(50).to_json(orient=\"records\")  # Convert sample of CSV data to JSON format\n",
    "\n",
    "        # Prepare LLM prompt\n",
    "        prompt = f\"\"\"\n",
    "        You are an AI assistant answering questions about CSV data.\n",
    "        Given the CSV sample: {csv_data}\n",
    "        Answer concisely: {question}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Query the Llama model\n",
    "        response = ollama.chat(model=MODEL_NAME, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "        \n",
    "        return response[\"message\"][\"content\"]  # âœ… Ensure correct response extraction\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"âŒ Error processing query: {str(e)}\"\n",
    "\n",
    "\n",
    "# Function to plot different graphs\n",
    "def plot_graph(x_axis, y_axis, graph_type):\n",
    "    global df\n",
    "    if df is None:\n",
    "        return \"âš ï¸ Please upload a CSV file first.\"\n",
    "    \n",
    "    if x_axis not in df.columns or y_axis not in df.columns:\n",
    "        return \"âš ï¸ Invalid column selection.\"\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    \n",
    "    try:\n",
    "        if graph_type == \"Scatter Plot\":\n",
    "            sns.scatterplot(data=df, x=x_axis, y=y_axis)\n",
    "        elif graph_type == \"Line Chart\":\n",
    "            sns.lineplot(data=df, x=x_axis, y=y_axis)\n",
    "        elif graph_type == \"Bar Chart\":\n",
    "            sns.barplot(data=df, x=x_axis, y=y_axis)\n",
    "        elif graph_type == \"Histogram\":\n",
    "            sns.histplot(df[x_axis], bins=20, kde=True)\n",
    "        \n",
    "        plt.xlabel(x_axis)\n",
    "        plt.ylabel(y_axis)\n",
    "        plt.title(f\"{graph_type}: {x_axis} vs {y_axis}\")\n",
    "        \n",
    "        # Save plot for display in Gradio\n",
    "        plot_path = \"plot.png\"\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        return plot_path\n",
    "    except Exception as e:\n",
    "        return f\"âŒ Error generating graph: {str(e)}\"\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# ğŸ¦™ AI-powered CSV Analysis with Llama 3 & Pydantic AI ğŸ¦™\")\n",
    "\n",
    "    file_input = gr.File(label=\"Upload CSV\", type=\"filepath\")\n",
    "    upload_button = gr.Button(\"Load CSV\")\n",
    "    status_output = gr.Textbox(label=\"Status\", interactive=False)\n",
    "\n",
    "    question_input = gr.Textbox(label=\"Ask a question about the CSV\")\n",
    "    submit_button = gr.Button(\"Submit\")\n",
    "    response_output = gr.Textbox(label=\"LLM Response\", interactive=False)\n",
    "\n",
    "    # Dynamic dropdown for column selection\n",
    "    x_axis_dropdown = gr.Dropdown(label=\"X-axis\", choices=[], interactive=True)\n",
    "    y_axis_dropdown = gr.Dropdown(label=\"Y-axis\", choices=[], interactive=True)\n",
    "    graph_type_dropdown = gr.Radio(\n",
    "        choices=[\"Scatter Plot\", \"Line Chart\", \"Bar Chart\", \"Histogram\"],\n",
    "        label=\"Graph Type\"\n",
    "    )\n",
    "\n",
    "    plot_button = gr.Button(\"Generate Graph\")\n",
    "    graph_output = gr.Image()\n",
    "\n",
    "    # Button actions\n",
    "    upload_button.click(load_csv, inputs=[file_input], outputs=[status_output, x_axis_dropdown, y_axis_dropdown])\n",
    "    submit_button.click(answer_query, inputs=[question_input], outputs=[response_output])\n",
    "    plot_button.click(plot_graph, inputs=[x_axis_dropdown, y_axis_dropdown, graph_type_dropdown], outputs=[graph_output])\n",
    "\n",
    "# Launch the app\n",
    "app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
